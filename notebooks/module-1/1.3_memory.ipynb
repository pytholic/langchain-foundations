{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444e549c",
   "metadata": {},
   "source": [
    "## Without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fbb273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e06e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0.0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2230b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=\"Hello my name is pytholic and my favorite color is black\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92244298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is pytholic and my favorite color is black', additional_kwargs={}, response_metadata={}, id='0e1eda34-5b9e-4924-886c-c28feccc5605'),\n",
      "              AIMessage(content=\"Hello Pytholic! It's nice to meet you. Black is a very classic and sophisticated favorite color. Is there anything I can help you with today?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cc-86c7-7fb2-9fab-b51a1cdd9b43-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 33, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180f69bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's my favorite color?\", additional_kwargs={}, response_metadata={}, id='70f071f2-90d5-4923-9f63-bb304a0d2fdf'),\n",
      "              AIMessage(content=\"I don't know your favorite color. As a large language model, I don't have access to personal information about you, including your preferences.\\n\\nTo tell me your favorite color, you'll need to tell me! ðŸ˜Š\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cc-8a58-7f30-8f1e-8628e1d90d11-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 8, 'output_tokens': 48, 'total_tokens': 56, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What's my favorite color?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]} \n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09283d",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962807fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=InMemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eae73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=\"Hello my name is pytholic and my favorite color is black\")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]},\n",
    "    config,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742724c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is pytholic and my favorite color is black', additional_kwargs={}, response_metadata={}, id='f10aaf6e-a084-4c37-b6b9-546044edec1a'),\n",
      "              AIMessage(content=\"Hello Pytholic! It's nice to meet you. Black is a very classic and sophisticated favorite color. Is there anything I can help you with today?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cd-8051-78d2-9a94-0931be6be2e4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 33, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c650a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is pytholic and my favorite color is black', additional_kwargs={}, response_metadata={}, id='f10aaf6e-a084-4c37-b6b9-546044edec1a'),\n",
      "              AIMessage(content=\"Hello Pytholic! It's nice to meet you. Black is a very classic and sophisticated favorite color. Is there anything I can help you with today?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cd-8051-78d2-9a94-0931be6be2e4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 33, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}}),\n",
      "              HumanMessage(content=\"What's my favorite color?\", additional_kwargs={}, response_metadata={}, id='328d50fb-a79c-48ab-a9e4-e411b824721d'),\n",
      "              AIMessage(content='Your favorite color is **black**.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cd-f54f-7180-9baa-527e99fc0498-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 7, 'total_tokens': 63, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What's my favorite color?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]},\n",
    "    config,  \n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e24a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is pytholic and my favorite color is black', additional_kwargs={}, response_metadata={}, id='f10aaf6e-a084-4c37-b6b9-546044edec1a'),\n",
      "              AIMessage(content=\"Hello Pytholic! It's nice to meet you. Black is a very classic and sophisticated favorite color. Is there anything I can help you with today?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cd-8051-78d2-9a94-0931be6be2e4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 33, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}}),\n",
      "              HumanMessage(content=\"What's my favorite color?\", additional_kwargs={}, response_metadata={}, id='328d50fb-a79c-48ab-a9e4-e411b824721d'),\n",
      "              AIMessage(content='Your favorite color is **black**.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7cd-f54f-7180-9baa-527e99fc0498-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 7, 'total_tokens': 63, 'input_token_details': {'cache_read': 0}}),\n",
      "              HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='3cb230a3-6b49-4414-b4cd-e13ea6f0f3c7'),\n",
      "              AIMessage(content='Your name is **Pytholic**.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019bf7ce-3850-79c1-9464-3fd89b458290-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 71, 'output_tokens': 8, 'total_tokens': 79, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What's my name?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]},\n",
    "    config,  \n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c08947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
